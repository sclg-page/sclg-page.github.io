<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="assets/main2.css">
    <link rel="stylesheet" href="assets/index2.css">
    <link rel="stylesheet" href="assets/index.css">
    <title>The Scene Language: Representing Scenes with Programs, Words, and Embeddings</title>
</head>
<body>
<!--==================== HEADER ====================-->
<header class="header" id="header">
    <nav class="nav container">
        <a href="#" class="nav__logo"><i class="nav__home_icon"></i></a>
        <div class="nav__menu" id="nav-menu">
            <ul class="nav__list grid">
                <li>
                    <a href="#text-cond" class="nav__link">Text-to-3D</a>
                </li>
                <li>
                    <a href="#4d" class="nav__link">Text-to-4D</a>
                </li>
                <li>
                    <a href="#renderers" class="nav__link">Renderers</a>
                </li>
                <li>
                    <a href="#image-cond" class="nav__link">Image-to-3D</a>
                </li>
                <li>
                    <a href="#pipeline" class="nav__link">Pipeline</a>
                </li>
                <li>
                    <a href="#style-transfer" class="nav__link">Style-transfer</a>
                </li>
                <li>
                    <a href="#baselines" class="nav__link">Baselines</a>
                </li>
            </ul>
            <i class="nav__close nav__icon nav__close_icon" id="nav-close"></i>
        </div>

        <div class="nav__btns">
            <i class="nav__toggle nav__icon nav__toggle_icon" id="nav-toggle"></i>
        </div>
    </nav>
</header>
<!--==================== MAIN ====================-->
<main class="main">
    <div class="paper__content-dummy"></div>
    <a class="anchor" id="home"></a>
    <section class="home section container">
        <div class="paper__title">
            The Scene Language: Representing Scenes with <br>Programs, Words, and Embeddings
        </div>
        <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
            <div class="paper__author">ICLR 2025 Anonymous Submission 809</div>
        </div>
        <br>
        <div class="paper__section-grid" style="grid-template-columns: 1fr; margin-left: 5%; margin-right: 5%">
            <div>
                <video controls loop muted autoplay src="resources/teaser.mp4#t=0.001" type="video/mp4"></video>
            </div>
        </div>

    </section>
    <a class="anchor" id="abstract"></a>
    <section class="section container">
        <!-- <div class="paper__section-title">Abstract</div> -->
        <div class="example-container abstract-content">
            <p>
                We introduce the Scene Language, a visual scene representation that concisely and precisely describes the structure, semantics, and identity of visual scenes.
                It represents a scene with three key components: a <span style="color: var(--prog-color)">program</span> that specifies the hierarchical and relational structure of entities in the scene,
                <span style="color: var(--word-color)">words</span> in natural language that summarize the semantic class of each entity, and <span style="color: var(--embd-color)">embeddings</span> that capture the visual identity of each entity.
                This representation can be <a href="#pipeline">inferred</a> from pre-trained language models via a training-free inference technique, given text or image inputs.
                The resulting scene can be <a href="#renderers">rendered</a> into images using traditional, neural, or hybrid graphics renderers.
                Together, this forms an automated system for high-quality <a href="#text-cond">3D</a> and <a href="#4d">4D</a> scene generation.
                <a href="#baselines">Compared</a> with existing representations like scene graphs, our proposed Scene Language generates complex scenes with higher fidelity,
                while explicitly modeling the scene structures to enable precise control and editing.
            </p>
            <br>
            <p>
                In the representation, a <i style="color: var(--prog-color)">program</i> declares a set of functions.
                Each function defines a semantic class of parts or objects, with natural language <i style="color: var(--word-color)">words</i> as the class name,
                by defining a mapping from neural <i style="color: var(--embd-color)">embeddings</i> capturing geometry and appearance details to class instances.
                The function body explicitly describes the computation process of
                how simpler semantic components are spatially transformed and composed into complex scenes.
            </p>
            <img src="resources/representation.png" alt="teaser">
            <p>
                Below shows various applications of the proposed <a href="#pipeline">pipeline</a>.
                Each video is a 360-degree scene rendering of the output scene.
                Clicking "Show Response" buttons reveals raw language model response,
                which contains the program and word components of the full representation.
            </p>
        </div>
    </section>
    <a class="anchor" id="text-cond"></a>
    <section class="section container">
        <div class="paper__section-title">Text-Conditioned Generation and Editing</div>
        <div class="example-container">
            <div class="paper__section-paragraph">
                <p>
                    This section shows results on text-conditioned 3D scene generation (left column)
                    and editing-instruction-following (right column), with text inputs shown below the corresponding output renderings.
                    Our representation provides an intuitive interface for controllable scene generation and editing, as
                    1) program function names correspond to words in natural language, offering interpretable semantic meanings,
                    and 2) program structure reflects scene structure, enabling significant scene changes through simple, one-line edits while preserving overall structure.
                </p>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/chessboard_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">A chessboard at game start</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/chessboard.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/chessboard_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Make a starting chess move</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/chessboard_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/fractal_tree_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">A fractal tree</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/fractal_tree.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/fractal_tree_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Make branching structure to be trinary and 3D</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/fractal_tree_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/Jenga_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">A 8-layer 3-color Jenga set at game start</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Jenga.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/Jenga_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Remove 2 blocks from second top layer and the tower should not fall</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Jenga_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/Moai_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Moai in Ahu Akivi, with slight variations</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Moai.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/Moai_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Make every two statues face to each other</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Moai_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/Son_of_Man_4_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">René Magritte The Son of Man</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Son_of_Man_4.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/Son_of_Man_4_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Move the apple to left</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/Son_of_Man_4_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/staircase_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Bramante Staircase, Vatican Museums</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/staircase.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/staircase_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Shrink staircase radius by 80%</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/staircase_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/edit/castle2_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Paul Klee Castle and Sun</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/castle2.txt')">Show Response</button>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/edit/castle2_edit.mp4#t=0.001" type="video/mp4"></video>
                    <p class="caption">Change all castles to be the middle one</p>
                    <button class="toggle-btn" onclick="toggleText(this, 'resources/edit/castle2_edit.txt')">Show Response</button>
                </div>
                <div class="text-content"></div>
            </div>
        </div>
    </section>
    <a class="anchor" id="4d"></a>
    <section class="section container">
        <div class="paper__section-title">Text-Conditioned 4D Generation</div>
        <div class="example-container">
            <div class="paper__section-paragraph">
                <p>
                    The proposed representation captures the structure not only for static, but also for dynamic scenes,
                    and can be applied for synthesizing 4D scenes conditioned on text inputs.
                    Comparisons with a 4D synthesis method, 4D-fy <a href="#ref8">[8]</a>, are shown below.
                    Different from 4D-fy which uses and implicit 4D representation,
                    ours explicitly represents the temporal correspondence of entities&mdash;Click the button below for tracking visualizations.
                </p>
            </div>
            <button id="globalToggleBtn" class="global-toggle-btn" onclick="toggleAllVideos()">Show All Tracking</button>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div class="tracking-video-container">
                    <video controls loop muted autoplay src="resources/4d/wind.mp4#t=0.001" type="video/mp4"></video>
                    <!--                    <button class="toggle-btn" onclick="toggleVideo(this)">Show Tracking</button>-->
                    <div><p class="subcaption">Ours</p></div>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/4D-fy/A_toy_wind_turbine.mp4#t=0.001" type="video/mp4"></video>
                    <div><p class="subcaption">4D-fy</p></div>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row">
                <p class="caption">A toy wind turbine</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/4d/wind.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div class="tracking-video-container">
                    <video controls loop muted autoplay src="resources/4d/carousel.mp4#t=0.001" type="video/mp4"></video>
                    <div><p class="subcaption">Ours</p></div>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/4D-fy/Carousel_with_a_small_canopy.mp4#t=0.001" type="video/mp4"></video>
                    <div><p class="subcaption">4D-fy</p></div>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row">
                <p class="caption">Carousel with a small canopy</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/4d/carousel.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div class="tracking-video-container">
                    <video controls loop muted autoplay src="resources/4d/solar.mp4#t=0.001" type="video/mp4"></video>
                    <div><p class="subcaption">Ours</p></div>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/4D-fy/Solar_system_model.mp4#t=0.001" type="video/mp4"></video>
                    <div><p class="subcaption">4D-fy</p></div>
                </div>
                <div class="text-content"></div>
            </div>
            <div class="video-row">
                <p class="caption">Solar system model</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/4d/solar.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
        </div>
    </section>
    <a class="anchor" id="renderers"></a>
    <section class="section container">
        <div class="paper__section-title">Alternative Renderers</div>
        <div class="example-container">
            <div class="paper__section-paragraph">
                <p>The same representation can be rendered with different renderers, showing the
                versatility of the proposed representation. Different renderers produce renderings that adhere
                to the same representation and therefore are visually
                aligned, while each exhibits a different imaging style.
                The following shows text-conditioned 3D generation results, with the renderer names and input text prompts shown below corresponding renderings.</p>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/minecraft/tennis_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Minecraft</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/minecraft/tennis_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">A detailed model of a tennis court</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/minecraft/tennis_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/minecraft/lecture_hall_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Minecraft</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/minecraft/lecture_hall_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">An interior scene of a university lecture hall</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/minecraft/lecture_hall_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
        </div>
<!--    </section>-->
<!--    <section class="section container">-->
<!--        <div class="paper__section-title">Alternative Renderers</div>-->
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Angulus_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Angulus_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">A scene inspired by The Angelus, Millet</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/text-cond/Angulus.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Goldfish_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Goldfish_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">The Goldfish by Henri Matisse</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/text-cond/Goldfish.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Morandi_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Morandi_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">A still life painting from Giorgio Morandi</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/text-cond/Morandi.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/desktop_setup_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/desktop_setup_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">A monitor, a keyboard, a mouse, a metal photo frame, and a plant on a wooden desk top</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/text-cond/desktop_setup.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(2, 1fr)">
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Lincoln4_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/text-cond/Lincoln4_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <p class="caption">Lincoln Memorial</p>
                <button class="toggle-btn" onclick="toggleText(this, 'resources/text-cond/Lincoln4_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
        </div>
    </section>
    <a class="anchor" id="image-cond"></a>
    <section class="section container">
        <div class="paper__section-title">Image-Conditioned Generation</div>
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
<!--                    <div class="image-wrapper">-->
                    <img src="resources/image-cond/image-ceramic_.png" alt="input">
<!--                    </div>-->
                    <p class="subcaption">Input image (credits: <a href="http://www.soniapedrazzini.it/index.html">Sonia Pedrazzini</a>)</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-ceramic_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-ceramic_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <button class="toggle-btn" onclick="toggleText(this, 'resources/image-cond/image-ceramic_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <img src="resources/image-cond/image-glasss_.png" alt="input">
                    <p class="caption">Input image (credits: <a href="https://en.wikipedia.org/wiki/Wayne_Thiebaud">Wayne Thiebaud</a>)</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-glasss_-mi.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Mitsuba</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-glasss_.mp4#t=0.001" type="video/mp4"></video>
                    <p class="subcaption">Gaussians</p>
                </div>
            </div>
            <div class="video-row">
                <button class="toggle-btn" onclick="toggleText(this, 'resources/image-cond/image-glasss_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <img src="resources/image-cond/image-6cokes_.png" alt="input">
                    <p class="caption">Input image</p>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-6cokes_-mi.mp4#t=0.001" type="video/mp4"></video>
                </div>
                <div>
                    <video controls loop muted autoplay src="resources/image-cond/image-6cokes_.mp4#t=0.001" type="video/mp4"></video>
                </div>
            </div>
            <div class="video-row">
                <button class="toggle-btn" onclick="toggleText(this, 'resources/image-cond/image-6cokes_.txt')">Show Response</button>
                <div class="text-content"></div>
            </div>
        </div>
    </section>
    <a class="anchor" id="pipeline"></a>
    <section class="section container">
        <div class="paper__section-title">Pipeline</div>
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src="resources/pipeline.png" alt="input">
                </div>
            </div>
            <div class="paper__section-paragraph">
                <p>
                    In the representation, a program consists of a set of semantic-aware functions identified by words.
                    A function maps embeddings to entities in the scene.
<!--                    In the representation, a program consists of a set of entity functions, each defining a class of entities-->
<!--                    and is associated with a word summarizing the semantic meaning of the defined class.-->
<!--                    Each function receives input neural embeddings that specify attributes and identity of a specific entity from the class,-->
<!--                    transforms and composes multiple sub-entities in the function body, and computes an entity output.-->
<!--                    <br>-->
                    To automatically <b>infer</b> the representation from text or image inputs, we convert the Scene Language grammar into Python and
                    prompt Claude 3.5 Sonnet <a href="#ref1">[1]</a> to generate the non-neural components.
                    Neural embeddings reside in the CLIP text embedding space <a href="#ref2">[2,3]</a>
                    and are obtained from texts via the CLIP text encoder or inverted from images with a pre-trained text-to-image model <a href="#ref4">[4,5]</a>.
                    Afterward, a program interpreter <b>executes</b> the program and computes a data object for the scene,
                    and a graphics renderer <b>renders</b> the data object into an image.
                </p>
            </div>
        </div>
    </section>
    <a class="anchor" id="style-transfer"></a>
    <section class="section container">
        <div class="paper__section-title">Style-transfer Editing</div>
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src="resources/style_page.jpg" alt="input">
                </div>
            </div>
            <div class="paper__section-paragraph">
                <p>
                    The proposed representation applies to image-prompted editing tasks such as style transfer. Edits can target partial or full scenes respectively, 
                    by updating embeddings for corresponding entites.
                </p>
            </div>
        </div>
    </section>
    <a class="anchor" id="baselines"></a>
    <section class="section container">
        <div class="paper__section-title">Baselines</div>
        <div class="paper__section-paragraph">
            <p>
                We evaluate our method on text-conditioned 3D generation tasks via a user study across 9 scenes shown below.
                We compare with two baseline methods: GraphDreamer <a href="#ref6">[6]</a>, which uses scene graphs for intermediate representation,
                and MVDream <a href="#ref7">[7]</a>, which directly generates scenes from text inputs.
                Input text prompts are show below output renderings.
                Our method achieves more favorable prompt alignment than the baselines and has a clear advantage in counting accuracy.
            </p>
        </div>
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0007.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">A 8-layer shelf</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0001.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">A 5x5 grid of white and black chess pieces on a square board</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0006.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">7 different sized Russian nesting dolls lined up</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0002.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">A nursery with 7x7 of potted plants</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0003.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">A room with four desks, each with one computer monitor on it</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0004.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">6 bottles of water arranged in a circle around a small potted plant</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0005.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">A 8-layer 3-color Jenga set at game start</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0000.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">15 coke cans stacking in a pyramid</p></div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <div>
                    <img src='resources/user_study/0008.gif'>
                </div>
            </div>
            <div class="paper__section-grid" style="grid-template-columns: repeat(3, 1fr)">
                <div>
                    <p class="subcaption">MVDream</p>
                </div>
                <div>
                    <p class="subcaption">GraphDreamer</p>
                </div>
                <div>
                    <p class="subcaption">Ours</p>
                </div>
            </div>
            <div><p class="caption">Three cokes in a close circle</p></div>
        </div>
    </section>
    <section class="section container">
        <div class="paper__section-title">Reference</div>
        <div class="example-container">
            <div class="paper__section-grid" style="grid-template-columns: repeat(1, 1fr)">
                <ol>
                    <li id="ref1">Anthropic. The Claude 3 model family: Opus, Sonnet, Haiku, 2024.</li>
                    <li id="ref2">Gadre, S. Y., Ilharco, G., Fang, A., Hayase, J., Smyrnis, G., Nguyen, T., ... & Schmidt, L. (2024). Datacomp: In search of the next generation of multimodal datasets.</li>
                    <li id="ref3">Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021). Learning transferable visual models from natural language supervision.</li>
                    <li id="ref4">Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2021). High-resolution image synthesis with latent diffusion models. </li>
                    <li id="ref5">Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A. H., Chechik, G., & Cohen-Or, D. (2022). An image is worth one word: Personalizing text-to-image generation using textual inversion. </li>
                    <li id="ref6">Gao, G., Liu, W., Chen, A., Geiger, A., & Schölkopf, B. (2024). GraphDreamer: Compositional 3D scene synthesis from scene graphs. </li>
                    <li id="ref7">Shi, Y., Wang, P., Ye, J., Long, M., Li, K., & Yang, X. (2023). MVDream: Multi-view diffusion for 3D generation. </li>
                </ol>
            </div>
        </div>
    </section>
</main>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<script src="assets/main2.js"></script>
<script src="assets/index.js"></script>
</body>
</html>
